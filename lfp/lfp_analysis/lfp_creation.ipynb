{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/blue/npadillacoreano/t.heeps/rehouse_code/diff_fam_social_memory_ephys/lfp/lfp_analysis\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/blue/npadillacoreano/t.heeps/rehouse_code/diff_fam_social_memory_ephys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lfp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbidict\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m bidict\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlfp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlfp_analysis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mLFP_collection\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mLFP_collection\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m \n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lfp'"
     ]
    }
   ],
   "source": [
    "from spectral_connectivity import Multitaper, Connectivity\n",
    "import importlib\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "import os\n",
    "from bidict import bidict\n",
    "import lfp.lfp_analysis.LFP_collection as LFP_collection\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from spectral_connectivity import Multitaper, Connectivity\n",
    "import importlib\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "import os\n",
    "from bidict import bidict\n",
    "import lfp.lfp_analysis.LFP_collection as LFP_collection\n",
    "import pickle \n",
    "def pickle_this(thing_to_pickle, file_name):\n",
    "    \"\"\"\n",
    "    Pickles things\n",
    "    Args (2):\n",
    "        thing_to_pickle: anything you want to pickle\n",
    "        file_name: str, filename that ends with .pkl\n",
    "    Returns:\n",
    "        none\n",
    "    \"\"\"\n",
    "    with open(file_name, \"wb\") as file:\n",
    "        pickle.dump(thing_to_pickle, file)\n",
    "def unpickle_this(pickle_file):\n",
    "    \"\"\"\n",
    "    Unpickles things\n",
    "    Args (1):\n",
    "        file_name: str, pickle filename that already exists and ends with .pkl\n",
    "    Returns:\n",
    "        pickled item\n",
    "    \"\"\"\n",
    "    with open(pickle_file, \"rb\") as file:\n",
    "        return pickle.load(file)\n",
    "\n",
    "df = pd.read_excel(r\"lfp/channel_mapping_sme.xlsx\")\n",
    "spike_cols = [col for col in df.columns if 'spike_interface_' in col.lower()]\n",
    "\n",
    "# Extract brain regions from column names\n",
    "# Assumes format 'spike_interface_REGION'\n",
    "brain_regions = [col.split('spike_interface_')[1] for col in spike_cols]\n",
    "\n",
    "# Create nested dictionary\n",
    "subject_to_channel_dict = {}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    subject = row['Subject'].astype(str)\n",
    "    # Initialize inner dictionary for this subject\n",
    "    subject_to_channel_dict[subject] = {}\n",
    "    \n",
    "    # Populate inner dictionary with brain region: spike value pairs\n",
    "    for col, region in zip(spike_cols, brain_regions):\n",
    "        subject_to_channel_dict[subject][region] = int(row[col])\n",
    "behavior_dicts = {}\n",
    "#pickle_this(subject_to_channel_dict)\n",
    "\n",
    "def make_recording_to_subj_dict(data_path):\n",
    "    recording_to_subject = {}\n",
    "    for root, dirs, files in os.walk(data_path):\n",
    "        for file in files:\n",
    "            if file.endswith('merged.rec'):\n",
    "                subject = str(int((file.split(\"_\")[0]))/10)\n",
    "                recording_to_subject[file] = subject\n",
    "                behavior_dicts[file] = {}\n",
    "    return recording_to_subject\n",
    "\n",
    "# def process(data_path):\n",
    "#     recording_to_subject = make_recording_to_subj_dict(data_path)\n",
    "#     print(recording_to_subject)\n",
    "#     collection = LFP_collection.LFPCollection(subject_to_channel_dict, data_path, recording_to_subject, 4)\n",
    "#     #collection.process()\n",
    "#     return collection    \n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SPECTRAL_CONNECTIVITY_ENABLE_GPU=true\n"
     ]
    }
   ],
   "source": [
    "%env SPECTRAL_CONNECTIVITY_ENABLE_GPU=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 20250618_113931_object_control_subj_1-2_merged.rec\n",
      "Found first timestamp\n"
     ]
    }
   ],
   "source": [
    "import lfp.lfp_analysis.LFP_recording as rec \n",
    "rec_path = r\"data/new_object_control_data/20250618_113931_object_control_subj_1-2_and_6-1.rec/20250618_113931_object_control_subj_1-2_merged.rec\"\n",
    "rec_object = rec.LFPRecording(subject = '1.2', channel_dict = {'mPFC': 2,\n",
    "                                 'NAc': 28,\n",
    "                                 'MD': 29,\n",
    "                                 'LH': 30,\n",
    "                                 'BLA': 31}, merged_rec_path = rec_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 20250618_113931_object_control_subj_1-2_merged.rec\n"
     ]
    }
   ],
   "source": [
    "trodes_rec = rec_object._read_trodes()\n",
    "traces = trodes_rec.get_traces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 32)\n",
      "ResampleRecording: 32 channels - 1 segments - 1.0kHz - 1939.501s\n"
     ]
    }
   ],
   "source": [
    "print(traces.shape)\n",
    "print(trodes_rec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m traces \u001b[38;5;241m=\u001b[39m \u001b[43mtrodes_rec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_traces\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m28\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m29\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m30\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m31\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_frame\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/blue/npadillacoreano/mcum/conda/envs/lfp_env/lib/python3.11/site-packages/spikeinterface/core/baserecording.py:159\u001b[0m, in \u001b[0;36mBaseRecording.get_traces\u001b[0;34m(self, segment_index, start_frame, end_frame, channel_ids, order, return_scaled, cast_unsigned)\u001b[0m\n\u001b[1;32m    157\u001b[0m segment_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_segment_index(segment_index)\n\u001b[1;32m    158\u001b[0m channel_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mids_to_indices(channel_ids, prefer_slice\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 159\u001b[0m rs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recording_segments\u001b[49m\u001b[43m[\u001b[49m\u001b[43msegment_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    160\u001b[0m traces \u001b[38;5;241m=\u001b[39m rs\u001b[38;5;241m.\u001b[39mget_traces(start_frame\u001b[38;5;241m=\u001b[39mstart_frame, end_frame\u001b[38;5;241m=\u001b[39mend_frame, channel_indices\u001b[38;5;241m=\u001b[39mchannel_indices)\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not list"
     ]
    }
   ],
   "source": [
    "traces = trodes_rec.get_traces(['2','28','29','30','31'], start_frame = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_object.traces.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = r\"data/new_object_control_data\"\n",
    "recording_to_subject = make_recording_to_subj_dict(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 22_object_merged.rec\n",
      "Found first timestamp\n",
      "Processing 44_object_merged.rec\n",
      "Found first timestamp\n",
      "Processing 32_object_merged.rec\n",
      "Found first timestamp\n",
      "Processing 31_object_merged.rec\n",
      "Found first timestamp\n",
      "Processing 23_object_merged.rec\n",
      "Found first timestamp\n",
      "Processing 41_object_merged.rec\n",
      "Found first timestamp\n"
     ]
    }
   ],
   "source": [
    "collection = LFP_collection.LFPCollection(subject_to_channel_dict, data_path, recording_to_subject, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 22_object_merged.rec\n",
      "Filename: /blue/npadillacoreano/mcum/SocialMemEphys/diff_fam_social_memory_ephys/lfp/lfp_analysis/preprocessor.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "    13    443.3 MiB    443.3 MiB           1   @profile\n",
      "    14                                         def preprocess(traces, threshold, scaling):\n",
      "    15                                             # brain_region_dict, traces = map_to_region(all_traces, subject_region_dict)\n",
      "    16    512.3 MiB     69.1 MiB           1       voltage_scaled_traces = scale_voltage(traces, scaling)\n",
      "    17    581.4 MiB     69.1 MiB           1       zscored_traces = zscore(voltage_scaled_traces)\n",
      "    18    650.3 MiB     68.9 MiB           1       filtered_traces = filter(zscored_traces, voltage_scaled_traces, threshold)\n",
      "    19    710.9 MiB     60.5 MiB           1       rms_traces = root_mean_square(filtered_traces)\n",
      "    20    710.9 MiB      0.0 MiB           1       return rms_traces\n",
      "\n",
      "\n",
      "RMS Traces calculated\n",
      "Power Calculated\n",
      "Coherence calcualatd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Maximum iterations reached. 3335 of 3620 converged\n",
      "Maximum iterations reached. 3424 of 3620 converged\n",
      "Maximum iterations reached. 3314 of 3620 converged\n",
      "Maximum iterations reached. 3319 of 3620 converged\n",
      "Maximum iterations reached. 3330 of 3620 converged\n",
      "Maximum iterations reached. 3271 of 3620 converged\n",
      "Maximum iterations reached. 3226 of 3620 converged\n",
      "Maximum iterations reached. 3350 of 3620 converged\n",
      "Maximum iterations reached. 3369 of 3620 converged\n",
      "Maximum iterations reached. 3250 of 3620 converged\n",
      " 17%|█▋        | 1/6 [00:43<03:38, 43.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granger's causality calculated\n",
      "processing 44_object_merged.rec\n",
      "Filename: /blue/npadillacoreano/mcum/SocialMemEphys/diff_fam_social_memory_ephys/lfp/lfp_analysis/preprocessor.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "    13   1693.6 MiB   1693.6 MiB           1   @profile\n",
      "    14                                         def preprocess(traces, threshold, scaling):\n",
      "    15                                             # brain_region_dict, traces = map_to_region(all_traces, subject_region_dict)\n",
      "    16   1762.6 MiB     68.9 MiB           1       voltage_scaled_traces = scale_voltage(traces, scaling)\n",
      "    17   1831.7 MiB     69.1 MiB           1       zscored_traces = zscore(voltage_scaled_traces)\n",
      "    18   1909.0 MiB     77.3 MiB           1       filtered_traces = filter(zscored_traces, voltage_scaled_traces, threshold)\n",
      "    19   1969.4 MiB     60.4 MiB           1       rms_traces = root_mean_square(filtered_traces)\n",
      "    20   1969.4 MiB      0.0 MiB           1       return rms_traces\n",
      "\n",
      "\n",
      "RMS Traces calculated\n",
      "Power Calculated\n",
      "Coherence calcualatd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Maximum iterations reached. 3529 of 3618 converged\n",
      "Maximum iterations reached. 3560 of 3618 converged\n",
      "Maximum iterations reached. 3559 of 3618 converged\n",
      "Maximum iterations reached. 3543 of 3618 converged\n",
      "Maximum iterations reached. 3531 of 3618 converged\n",
      "Maximum iterations reached. 3549 of 3618 converged\n",
      "Maximum iterations reached. 3533 of 3618 converged\n",
      "Maximum iterations reached. 3582 of 3618 converged\n",
      "Maximum iterations reached. 3579 of 3618 converged\n",
      "Maximum iterations reached. 3570 of 3618 converged\n",
      " 33%|███▎      | 2/6 [01:08<02:10, 32.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granger's causality calculated\n",
      "processing 32_object_merged.rec\n",
      "Filename: /blue/npadillacoreano/mcum/SocialMemEphys/diff_fam_social_memory_ephys/lfp/lfp_analysis/preprocessor.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "    13   2521.7 MiB   2521.7 MiB           1   @profile\n",
      "    14                                         def preprocess(traces, threshold, scaling):\n",
      "    15                                             # brain_region_dict, traces = map_to_region(all_traces, subject_region_dict)\n",
      "    16   2591.5 MiB     69.8 MiB           1       voltage_scaled_traces = scale_voltage(traces, scaling)\n",
      "    17   2661.4 MiB     69.9 MiB           1       zscored_traces = zscore(voltage_scaled_traces)\n",
      "    18   2731.2 MiB     69.8 MiB           1       filtered_traces = filter(zscored_traces, voltage_scaled_traces, threshold)\n",
      "    19   2801.0 MiB     69.8 MiB           1       rms_traces = root_mean_square(filtered_traces)\n",
      "    20   2801.0 MiB      0.0 MiB           1       return rms_traces\n",
      "\n",
      "\n",
      "RMS Traces calculated\n",
      "Power Calculated\n",
      "Coherence calcualatd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Maximum iterations reached. 3330 of 3660 converged\n",
      "Maximum iterations reached. 3327 of 3660 converged\n",
      "Maximum iterations reached. 3384 of 3660 converged\n",
      "Maximum iterations reached. 3451 of 3660 converged\n",
      "Maximum iterations reached. 3278 of 3660 converged\n",
      "Maximum iterations reached. 3310 of 3660 converged\n",
      "Maximum iterations reached. 3328 of 3660 converged\n",
      "Maximum iterations reached. 3320 of 3660 converged\n",
      "Maximum iterations reached. 3351 of 3660 converged\n",
      "Maximum iterations reached. 3422 of 3660 converged\n",
      " 50%|█████     | 3/6 [01:33<01:27, 29.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granger's causality calculated\n",
      "processing 31_object_merged.rec\n",
      "Filename: /blue/npadillacoreano/mcum/SocialMemEphys/diff_fam_social_memory_ephys/lfp/lfp_analysis/preprocessor.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "    13   3359.6 MiB   3359.6 MiB           1   @profile\n",
      "    14                                         def preprocess(traces, threshold, scaling):\n",
      "    15                                             # brain_region_dict, traces = map_to_region(all_traces, subject_region_dict)\n",
      "    16   3429.4 MiB     69.8 MiB           1       voltage_scaled_traces = scale_voltage(traces, scaling)\n",
      "    17   3499.3 MiB     69.9 MiB           1       zscored_traces = zscore(voltage_scaled_traces)\n",
      "    18   3577.7 MiB     78.4 MiB           1       filtered_traces = filter(zscored_traces, voltage_scaled_traces, threshold)\n",
      "    19   3638.9 MiB     61.2 MiB           1       rms_traces = root_mean_square(filtered_traces)\n",
      "    20   3638.9 MiB      0.0 MiB           1       return rms_traces\n",
      "\n",
      "\n",
      "RMS Traces calculated\n",
      "Power Calculated\n",
      "Coherence calcualatd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Maximum iterations reached. 3592 of 3659 converged\n",
      "Maximum iterations reached. 3527 of 3659 converged\n",
      "Maximum iterations reached. 3581 of 3659 converged\n",
      "Maximum iterations reached. 3562 of 3659 converged\n",
      "Maximum iterations reached. 3528 of 3659 converged\n",
      "Maximum iterations reached. 3582 of 3659 converged\n",
      "Maximum iterations reached. 3558 of 3659 converged\n",
      "Maximum iterations reached. 3507 of 3659 converged\n",
      "Maximum iterations reached. 3480 of 3659 converged\n",
      "Maximum iterations reached. 3542 of 3659 converged\n",
      " 67%|██████▋   | 4/6 [01:59<00:55, 27.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granger's causality calculated\n",
      "processing 23_object_merged.rec\n",
      "Filename: /blue/npadillacoreano/mcum/SocialMemEphys/diff_fam_social_memory_ephys/lfp/lfp_analysis/preprocessor.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "    13   4197.3 MiB   4197.3 MiB           1   @profile\n",
      "    14                                         def preprocess(traces, threshold, scaling):\n",
      "    15                                             # brain_region_dict, traces = map_to_region(all_traces, subject_region_dict)\n",
      "    16   4267.0 MiB     69.8 MiB           1       voltage_scaled_traces = scale_voltage(traces, scaling)\n",
      "    17   4337.0 MiB     70.0 MiB           1       zscored_traces = zscore(voltage_scaled_traces)\n",
      "    18   4415.3 MiB     78.3 MiB           1       filtered_traces = filter(zscored_traces, voltage_scaled_traces, threshold)\n",
      "    19   4476.6 MiB     61.2 MiB           1       rms_traces = root_mean_square(filtered_traces)\n",
      "    20   4476.6 MiB      0.0 MiB           1       return rms_traces\n",
      "\n",
      "\n",
      "RMS Traces calculated\n",
      "Power Calculated\n",
      "Coherence calcualatd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Maximum iterations reached. 3632 of 3660 converged\n",
      "Maximum iterations reached. 3640 of 3660 converged\n",
      "Maximum iterations reached. 3632 of 3660 converged\n",
      "Maximum iterations reached. 3582 of 3660 converged\n",
      "Maximum iterations reached. 3630 of 3660 converged\n",
      "Maximum iterations reached. 3636 of 3660 converged\n",
      "Maximum iterations reached. 3586 of 3660 converged\n",
      "Maximum iterations reached. 3642 of 3660 converged\n",
      "Maximum iterations reached. 3602 of 3660 converged\n",
      "Maximum iterations reached. 3589 of 3660 converged\n",
      " 83%|████████▎ | 5/6 [02:24<00:26, 26.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granger's causality calculated\n",
      "processing 41_object_merged.rec\n",
      "Filename: /blue/npadillacoreano/mcum/SocialMemEphys/diff_fam_social_memory_ephys/lfp/lfp_analysis/preprocessor.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "    13   5035.2 MiB   5035.2 MiB           1   @profile\n",
      "    14                                         def preprocess(traces, threshold, scaling):\n",
      "    15                                             # brain_region_dict, traces = map_to_region(all_traces, subject_region_dict)\n",
      "    16   5104.9 MiB     69.7 MiB           1       voltage_scaled_traces = scale_voltage(traces, scaling)\n",
      "    17   5174.9 MiB     69.9 MiB           1       zscored_traces = zscore(voltage_scaled_traces)\n",
      "    18   5253.1 MiB     78.3 MiB           1       filtered_traces = filter(zscored_traces, voltage_scaled_traces, threshold)\n",
      "    19   5314.4 MiB     61.3 MiB           1       rms_traces = root_mean_square(filtered_traces)\n",
      "    20   5314.4 MiB      0.0 MiB           1       return rms_traces\n",
      "\n",
      "\n",
      "RMS Traces calculated\n",
      "Power Calculated\n",
      "Coherence calcualatd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Maximum iterations reached. 3608 of 3659 converged\n",
      "Maximum iterations reached. 3628 of 3659 converged\n",
      "Maximum iterations reached. 3618 of 3659 converged\n",
      "Maximum iterations reached. 2865 of 3659 converged\n",
      "Maximum iterations reached. 3605 of 3659 converged\n",
      "Maximum iterations reached. 3602 of 3659 converged\n",
      "Maximum iterations reached. 2854 of 3659 converged\n",
      "Maximum iterations reached. 3637 of 3659 converged\n",
      "Maximum iterations reached. 2879 of 3659 converged\n",
      "Maximum iterations reached. 2870 of 3659 converged\n",
      "100%|██████████| 6/6 [02:49<00:00, 28.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granger's causality calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "collection.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_collection.LFPCollection.save_to_json(collection, r\"data/object_control_sd5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (lfp_export_env)",
   "language": "python",
   "name": "lfp_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
