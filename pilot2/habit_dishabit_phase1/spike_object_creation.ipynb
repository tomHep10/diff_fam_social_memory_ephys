{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import os\n",
    "from scipy.stats import sem\n",
    "from matplotlib.lines import Line2D\n",
    "import sys\n",
    "import pickle\n",
    "import spike.spike_analysis.firing_rate_calculations as fr\n",
    "import spike.spike_analysis.spike_collection as collection\n",
    "import spike.spike_analysis.spike_recording as recording\n",
    "\n",
    "import spike.spike_analysis.pca_trajectories as pca_trajectories\n",
    "import pickle\n",
    "\n",
    "def hex_2_rgb(hex_color): # Orange color\n",
    "    rgb_color = tuple(int(hex_color[i:i+2], 16) / 255.0 for i in (1, 3, 5))\n",
    "    return rgb_color\n",
    "\n",
    "def pickle_this(thing_to_pickle, file_name):\n",
    "    \"\"\"\n",
    "    Pickles things\n",
    "    Args (2):\n",
    "        thing_to_pickle: anything you want to pickle\n",
    "        file_name: str, filename that ends with .pkl\n",
    "    Returns:\n",
    "        none\n",
    "    \"\"\"\n",
    "    with open(file_name,'wb') as file:\n",
    "        pickle.dump(thing_to_pickle, file)\n",
    "\n",
    "def unpickle_this(pickle_file):\n",
    "    \"\"\"\n",
    "    Unpickles things\n",
    "    Args (1):\n",
    "        file_name: str, pickle filename that already exists and ends with .pkl\n",
    "    Returns:\n",
    "        pickled item\n",
    "    \"\"\"\n",
    "    with open(pickle_file, 'rb') as file:\n",
    "        return(pickle.load(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading  11_cage_p1_merged.rec\n",
      "loading  12_cage_p1_merged.rec\n",
      "loading  13_cage_p1_merged.rec\n",
      "loading  21_cage_p1_merged.rec\n",
      "loading  22_cage_p1_merged.rec\n",
      "loading  23_cage_p1_merged.rec\n",
      "23_cage_p1_merged.rec has no good units\n",
      "and will not be included in the collection\n",
      "loading  24_cage_p1_merged.rec\n",
      "loading  31_cage_p1_merged.rec\n",
      "loading  32_cage_p1_merged.rec\n",
      "loading  33_cage_p1_merged.rec\n",
      "loading  41_cage_p1_merged.rec\n",
      "loading  44_cage_p1_merged.rec\n",
      "Please assign event dictionaries to each recording\n",
      "as recording.event_dict\n",
      "event_dict = {event name(str): np.array[[start(ms), stop(ms)]...]\n",
      "Please assign subjects to each recording as recording.subject\n",
      "loading  11_nov_p1_merged.rec\n",
      "loading  12_nov_p1_merged.rec\n",
      "loading  13_nov_p1_merged.rec\n",
      "loading  21_nov_p1_merged.rec\n",
      "loading  22_nov_p1_merged.rec\n",
      "loading  23_nov_p1_merged.rec\n",
      "23_nov_p1_merged.rec has no good units\n",
      "and will not be included in the collection\n",
      "loading  24_nov_p1_merged.rec\n",
      "loading  32_nov_p1_merged.rec\n",
      "loading  33_nov_p1_merged.rec\n",
      "loading  41_nov_p1_merged.rec\n",
      "loading  44_nov_p1_merged.rec\n",
      "Please assign event dictionaries to each recording\n",
      "as recording.event_dict\n",
      "event_dict = {event name(str): np.array[[start(ms), stop(ms)]...]\n",
      "Please assign subjects to each recording as recording.subject\n"
     ]
    }
   ],
   "source": [
    "cagemate_collection = collection.SpikeCollection(r\"C:\\Users\\megha\\UFL Dropbox\\Meghan Cum\\Padilla-Coreano Lab\\2024\\Cum_SocialMemEphys_pilot2\\Habituation_Dishabituation (phase 1)\\spike_data\\sorted\\cagemate\")\n",
    "novel_collection = collection.SpikeCollection(r\"C:\\Users\\megha\\UFL Dropbox\\Meghan Cum\\Padilla-Coreano Lab\\2024\\Cum_SocialMemEphys_pilot2\\Habituation_Dishabituation (phase 1)\\spike_data\\sorted\\novel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['11_cage_p1_aggregated', '11_nov_p1_aggregated', '12_cage_p1_aggregated', '12_nov_p1_aggregated', '13_cage_p1_aggregated', '13_nov_p1_aggregated', '21_cage_p1_aggregated', '21_nov_p1_aggregated', '22_cage_p1_aggregated', '22_nov_p1_aggregated', '23_cage_p1_aggregated', '23_nov_p1_aggregated', '24_cage_p1_aggregated', '24_nov_p1_aggregated', '31_cage_p1_aggregated', '31_nov_p1_aggregated', '32_cage_p1_aggregated', '32_nov_p1_aggregated', '33_cage_p1_aggregated', '33_nov_p1_aggregated', '41_cage_p1_aggregated', '41_nov_p1_aggregated', '44_cage_p1_aggregated', '44_nov_p1_aggregated'])\n"
     ]
    }
   ],
   "source": [
    "behavior_dicts = unpickle_this('behavior_dicts.pkl')\n",
    "print(behavior_dicts.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11_cage_p1_aggregated\n",
      "12_cage_p1_aggregated\n",
      "13_cage_p1_aggregated\n",
      "21_cage_p1_aggregated\n",
      "22_cage_p1_aggregated\n",
      "24_cage_p1_aggregated\n",
      "31_cage_p1_aggregated\n",
      "32_cage_p1_aggregated\n",
      "33_cage_p1_aggregated\n",
      "41_cage_p1_aggregated\n",
      "44_cage_p1_aggregated\n",
      "11_nov_p1_aggregated\n",
      "12_nov_p1_aggregated\n",
      "13_nov_p1_aggregated\n",
      "21_nov_p1_aggregated\n",
      "22_nov_p1_aggregated\n",
      "24_nov_p1_aggregated\n",
      "32_nov_p1_aggregated\n",
      "33_nov_p1_aggregated\n",
      "41_nov_p1_aggregated\n",
      "44_nov_p1_aggregated\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for recording in cagemate_collection.collection:\n",
    "    subject = str(int(recording.name.split('_')[0])/10)\n",
    "    recording_pattern = (recording.name.split('_')[0] + '_' +\n",
    "                         recording.name.split('_')[1] + '_' +\n",
    "                         recording.name.split('_')[2] + '_' +\n",
    "                         'aggregated')\n",
    "    recording.event_dict = behavior_dicts[recording_pattern]\n",
    "    print(recording_pattern)\n",
    "    recording.subject = subject\n",
    "\n",
    "for recording in novel_collection.collection:\n",
    "    subject = str(int(recording.name.split('_')[0])/10)\n",
    "    recording_pattern = (recording.name.split('_')[0] + '_' +\n",
    "                         recording.name.split('_')[1] + '_' +\n",
    "                         recording.name.split('_')[2] + '_' +\n",
    "                         'aggregated')\n",
    "    recording.event_dict = behavior_dicts[recording_pattern]\n",
    "    print(recording_pattern)\n",
    "    recording.subject = subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_this(novel_collection, 'novel_collection.pkl')\n",
    "pickle_this(cagemate_collection, 'cagemate_collection.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ephys_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
